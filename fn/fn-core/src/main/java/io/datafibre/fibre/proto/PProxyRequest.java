// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: internal_service.proto

package io.datafibre.fibre.proto;

/**
 * Protobuf type {@code starrocks.PProxyRequest}
 */
public final class PProxyRequest extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:starrocks.PProxyRequest)
    PProxyRequestOrBuilder {
private static final long serialVersionUID = 0L;
  // Use PProxyRequest.newBuilder() to construct.
  private PProxyRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private PProxyRequest() {
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(
      UnusedPrivateParameter unused) {
    return new PProxyRequest();
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return this.unknownFields;
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return io.datafibre.fibre.proto.InternalService.internal_static_starrocks_PProxyRequest_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return io.datafibre.fibre.proto.InternalService.internal_static_starrocks_PProxyRequest_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            io.datafibre.fibre.proto.PProxyRequest.class, io.datafibre.fibre.proto.PProxyRequest.Builder.class);
  }

  private int bitField0_;
  public static final int KAFKA_META_REQUEST_FIELD_NUMBER = 1;
  private io.datafibre.fibre.proto.PKafkaMetaProxyRequest kafkaMetaRequest_;
  /**
   * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
   * @return Whether the kafkaMetaRequest field is set.
   */
  @java.lang.Override
  public boolean hasKafkaMetaRequest() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
   * @return The kafkaMetaRequest.
   */
  @java.lang.Override
  public io.datafibre.fibre.proto.PKafkaMetaProxyRequest getKafkaMetaRequest() {
    return kafkaMetaRequest_ == null ? io.datafibre.fibre.proto.PKafkaMetaProxyRequest.getDefaultInstance() : kafkaMetaRequest_;
  }
  /**
   * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
   */
  @java.lang.Override
  public io.datafibre.fibre.proto.PKafkaMetaProxyRequestOrBuilder getKafkaMetaRequestOrBuilder() {
    return kafkaMetaRequest_ == null ? io.datafibre.fibre.proto.PKafkaMetaProxyRequest.getDefaultInstance() : kafkaMetaRequest_;
  }

  public static final int KAFKA_OFFSET_REQUEST_FIELD_NUMBER = 101;
  private io.datafibre.fibre.proto.PKafkaOffsetProxyRequest kafkaOffsetRequest_;
  /**
   * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
   * @return Whether the kafkaOffsetRequest field is set.
   */
  @java.lang.Override
  public boolean hasKafkaOffsetRequest() {
    return ((bitField0_ & 0x00000002) != 0);
  }
  /**
   * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
   * @return The kafkaOffsetRequest.
   */
  @java.lang.Override
  public io.datafibre.fibre.proto.PKafkaOffsetProxyRequest getKafkaOffsetRequest() {
    return kafkaOffsetRequest_ == null ? io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.getDefaultInstance() : kafkaOffsetRequest_;
  }
  /**
   * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
   */
  @java.lang.Override
  public io.datafibre.fibre.proto.PKafkaOffsetProxyRequestOrBuilder getKafkaOffsetRequestOrBuilder() {
    return kafkaOffsetRequest_ == null ? io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.getDefaultInstance() : kafkaOffsetRequest_;
  }

  public static final int KAFKA_OFFSET_BATCH_REQUEST_FIELD_NUMBER = 102;
  private io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest kafkaOffsetBatchRequest_;
  /**
   * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
   * @return Whether the kafkaOffsetBatchRequest field is set.
   */
  @java.lang.Override
  public boolean hasKafkaOffsetBatchRequest() {
    return ((bitField0_ & 0x00000004) != 0);
  }
  /**
   * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
   * @return The kafkaOffsetBatchRequest.
   */
  @java.lang.Override
  public io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest getKafkaOffsetBatchRequest() {
    return kafkaOffsetBatchRequest_ == null ? io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.getDefaultInstance() : kafkaOffsetBatchRequest_;
  }
  /**
   * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
   */
  @java.lang.Override
  public io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequestOrBuilder getKafkaOffsetBatchRequestOrBuilder() {
    return kafkaOffsetBatchRequest_ == null ? io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.getDefaultInstance() : kafkaOffsetBatchRequest_;
  }

  public static final int TIMEOUT_FIELD_NUMBER = 103;
  private long timeout_;
  /**
   * <code>optional int64 timeout = 103;</code>
   * @return Whether the timeout field is set.
   */
  @java.lang.Override
  public boolean hasTimeout() {
    return ((bitField0_ & 0x00000008) != 0);
  }
  /**
   * <code>optional int64 timeout = 103;</code>
   * @return The timeout.
   */
  @java.lang.Override
  public long getTimeout() {
    return timeout_;
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    if (hasKafkaMetaRequest()) {
      if (!getKafkaMetaRequest().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
    }
    if (hasKafkaOffsetRequest()) {
      if (!getKafkaOffsetRequest().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
    }
    if (hasKafkaOffsetBatchRequest()) {
      if (!getKafkaOffsetBatchRequest().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
    }
    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (((bitField0_ & 0x00000001) != 0)) {
      output.writeMessage(1, getKafkaMetaRequest());
    }
    if (((bitField0_ & 0x00000002) != 0)) {
      output.writeMessage(101, getKafkaOffsetRequest());
    }
    if (((bitField0_ & 0x00000004) != 0)) {
      output.writeMessage(102, getKafkaOffsetBatchRequest());
    }
    if (((bitField0_ & 0x00000008) != 0)) {
      output.writeInt64(103, timeout_);
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (((bitField0_ & 0x00000001) != 0)) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(1, getKafkaMetaRequest());
    }
    if (((bitField0_ & 0x00000002) != 0)) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(101, getKafkaOffsetRequest());
    }
    if (((bitField0_ & 0x00000004) != 0)) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(102, getKafkaOffsetBatchRequest());
    }
    if (((bitField0_ & 0x00000008) != 0)) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt64Size(103, timeout_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof io.datafibre.fibre.proto.PProxyRequest)) {
      return super.equals(obj);
    }
    io.datafibre.fibre.proto.PProxyRequest other = (io.datafibre.fibre.proto.PProxyRequest) obj;

    if (hasKafkaMetaRequest() != other.hasKafkaMetaRequest()) return false;
    if (hasKafkaMetaRequest()) {
      if (!getKafkaMetaRequest()
          .equals(other.getKafkaMetaRequest())) return false;
    }
    if (hasKafkaOffsetRequest() != other.hasKafkaOffsetRequest()) return false;
    if (hasKafkaOffsetRequest()) {
      if (!getKafkaOffsetRequest()
          .equals(other.getKafkaOffsetRequest())) return false;
    }
    if (hasKafkaOffsetBatchRequest() != other.hasKafkaOffsetBatchRequest()) return false;
    if (hasKafkaOffsetBatchRequest()) {
      if (!getKafkaOffsetBatchRequest()
          .equals(other.getKafkaOffsetBatchRequest())) return false;
    }
    if (hasTimeout() != other.hasTimeout()) return false;
    if (hasTimeout()) {
      if (getTimeout()
          != other.getTimeout()) return false;
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    if (hasKafkaMetaRequest()) {
      hash = (37 * hash) + KAFKA_META_REQUEST_FIELD_NUMBER;
      hash = (53 * hash) + getKafkaMetaRequest().hashCode();
    }
    if (hasKafkaOffsetRequest()) {
      hash = (37 * hash) + KAFKA_OFFSET_REQUEST_FIELD_NUMBER;
      hash = (53 * hash) + getKafkaOffsetRequest().hashCode();
    }
    if (hasKafkaOffsetBatchRequest()) {
      hash = (37 * hash) + KAFKA_OFFSET_BATCH_REQUEST_FIELD_NUMBER;
      hash = (53 * hash) + getKafkaOffsetBatchRequest().hashCode();
    }
    if (hasTimeout()) {
      hash = (37 * hash) + TIMEOUT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getTimeout());
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static io.datafibre.fibre.proto.PProxyRequest parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(io.datafibre.fibre.proto.PProxyRequest prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * Protobuf type {@code starrocks.PProxyRequest}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:starrocks.PProxyRequest)
      io.datafibre.fibre.proto.PProxyRequestOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return io.datafibre.fibre.proto.InternalService.internal_static_starrocks_PProxyRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return io.datafibre.fibre.proto.InternalService.internal_static_starrocks_PProxyRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              io.datafibre.fibre.proto.PProxyRequest.class, io.datafibre.fibre.proto.PProxyRequest.Builder.class);
    }

    // Construct using io.datafibre.fibre.proto.PProxyRequest.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3
              .alwaysUseFieldBuilders) {
        getKafkaMetaRequestFieldBuilder();
        getKafkaOffsetRequestFieldBuilder();
        getKafkaOffsetBatchRequestFieldBuilder();
      }
    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      if (kafkaMetaRequestBuilder_ == null) {
        kafkaMetaRequest_ = null;
      } else {
        kafkaMetaRequestBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000001);
      if (kafkaOffsetRequestBuilder_ == null) {
        kafkaOffsetRequest_ = null;
      } else {
        kafkaOffsetRequestBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000002);
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        kafkaOffsetBatchRequest_ = null;
      } else {
        kafkaOffsetBatchRequestBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000004);
      timeout_ = 0L;
      bitField0_ = (bitField0_ & ~0x00000008);
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return io.datafibre.fibre.proto.InternalService.internal_static_starrocks_PProxyRequest_descriptor;
    }

    @java.lang.Override
    public io.datafibre.fibre.proto.PProxyRequest getDefaultInstanceForType() {
      return io.datafibre.fibre.proto.PProxyRequest.getDefaultInstance();
    }

    @java.lang.Override
    public io.datafibre.fibre.proto.PProxyRequest build() {
      io.datafibre.fibre.proto.PProxyRequest result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public io.datafibre.fibre.proto.PProxyRequest buildPartial() {
      io.datafibre.fibre.proto.PProxyRequest result = new io.datafibre.fibre.proto.PProxyRequest(this);
      int from_bitField0_ = bitField0_;
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        if (kafkaMetaRequestBuilder_ == null) {
          result.kafkaMetaRequest_ = kafkaMetaRequest_;
        } else {
          result.kafkaMetaRequest_ = kafkaMetaRequestBuilder_.build();
        }
        to_bitField0_ |= 0x00000001;
      }
      if (((from_bitField0_ & 0x00000002) != 0)) {
        if (kafkaOffsetRequestBuilder_ == null) {
          result.kafkaOffsetRequest_ = kafkaOffsetRequest_;
        } else {
          result.kafkaOffsetRequest_ = kafkaOffsetRequestBuilder_.build();
        }
        to_bitField0_ |= 0x00000002;
      }
      if (((from_bitField0_ & 0x00000004) != 0)) {
        if (kafkaOffsetBatchRequestBuilder_ == null) {
          result.kafkaOffsetBatchRequest_ = kafkaOffsetBatchRequest_;
        } else {
          result.kafkaOffsetBatchRequest_ = kafkaOffsetBatchRequestBuilder_.build();
        }
        to_bitField0_ |= 0x00000004;
      }
      if (((from_bitField0_ & 0x00000008) != 0)) {
        result.timeout_ = timeout_;
        to_bitField0_ |= 0x00000008;
      }
      result.bitField0_ = to_bitField0_;
      onBuilt();
      return result;
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }
    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.setField(field, value);
    }
    @java.lang.Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @java.lang.Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }
    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof io.datafibre.fibre.proto.PProxyRequest) {
        return mergeFrom((io.datafibre.fibre.proto.PProxyRequest)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(io.datafibre.fibre.proto.PProxyRequest other) {
      if (other == io.datafibre.fibre.proto.PProxyRequest.getDefaultInstance()) return this;
      if (other.hasKafkaMetaRequest()) {
        mergeKafkaMetaRequest(other.getKafkaMetaRequest());
      }
      if (other.hasKafkaOffsetRequest()) {
        mergeKafkaOffsetRequest(other.getKafkaOffsetRequest());
      }
      if (other.hasKafkaOffsetBatchRequest()) {
        mergeKafkaOffsetBatchRequest(other.getKafkaOffsetBatchRequest());
      }
      if (other.hasTimeout()) {
        setTimeout(other.getTimeout());
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      if (hasKafkaMetaRequest()) {
        if (!getKafkaMetaRequest().isInitialized()) {
          return false;
        }
      }
      if (hasKafkaOffsetRequest()) {
        if (!getKafkaOffsetRequest().isInitialized()) {
          return false;
        }
      }
      if (hasKafkaOffsetBatchRequest()) {
        if (!getKafkaOffsetBatchRequest().isInitialized()) {
          return false;
        }
      }
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              input.readMessage(
                  getKafkaMetaRequestFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000001;
              break;
            } // case 10
            case 810: {
              input.readMessage(
                  getKafkaOffsetRequestFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000002;
              break;
            } // case 810
            case 818: {
              input.readMessage(
                  getKafkaOffsetBatchRequestFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000004;
              break;
            } // case 818
            case 824: {
              timeout_ = input.readInt64();
              bitField0_ |= 0x00000008;
              break;
            } // case 824
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int bitField0_;

    private io.datafibre.fibre.proto.PKafkaMetaProxyRequest kafkaMetaRequest_;
    private com.google.protobuf.SingleFieldBuilderV3<
        io.datafibre.fibre.proto.PKafkaMetaProxyRequest, io.datafibre.fibre.proto.PKafkaMetaProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaMetaProxyRequestOrBuilder> kafkaMetaRequestBuilder_;
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     * @return Whether the kafkaMetaRequest field is set.
     */
    public boolean hasKafkaMetaRequest() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     * @return The kafkaMetaRequest.
     */
    public io.datafibre.fibre.proto.PKafkaMetaProxyRequest getKafkaMetaRequest() {
      if (kafkaMetaRequestBuilder_ == null) {
        return kafkaMetaRequest_ == null ? io.datafibre.fibre.proto.PKafkaMetaProxyRequest.getDefaultInstance() : kafkaMetaRequest_;
      } else {
        return kafkaMetaRequestBuilder_.getMessage();
      }
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    public Builder setKafkaMetaRequest(io.datafibre.fibre.proto.PKafkaMetaProxyRequest value) {
      if (kafkaMetaRequestBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        kafkaMetaRequest_ = value;
        onChanged();
      } else {
        kafkaMetaRequestBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000001;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    public Builder setKafkaMetaRequest(
        io.datafibre.fibre.proto.PKafkaMetaProxyRequest.Builder builderForValue) {
      if (kafkaMetaRequestBuilder_ == null) {
        kafkaMetaRequest_ = builderForValue.build();
        onChanged();
      } else {
        kafkaMetaRequestBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000001;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    public Builder mergeKafkaMetaRequest(io.datafibre.fibre.proto.PKafkaMetaProxyRequest value) {
      if (kafkaMetaRequestBuilder_ == null) {
        if (((bitField0_ & 0x00000001) != 0) &&
            kafkaMetaRequest_ != null &&
            kafkaMetaRequest_ != io.datafibre.fibre.proto.PKafkaMetaProxyRequest.getDefaultInstance()) {
          kafkaMetaRequest_ =
            io.datafibre.fibre.proto.PKafkaMetaProxyRequest.newBuilder(kafkaMetaRequest_).mergeFrom(value).buildPartial();
        } else {
          kafkaMetaRequest_ = value;
        }
        onChanged();
      } else {
        kafkaMetaRequestBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000001;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    public Builder clearKafkaMetaRequest() {
      if (kafkaMetaRequestBuilder_ == null) {
        kafkaMetaRequest_ = null;
        onChanged();
      } else {
        kafkaMetaRequestBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000001);
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    public io.datafibre.fibre.proto.PKafkaMetaProxyRequest.Builder getKafkaMetaRequestBuilder() {
      bitField0_ |= 0x00000001;
      onChanged();
      return getKafkaMetaRequestFieldBuilder().getBuilder();
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    public io.datafibre.fibre.proto.PKafkaMetaProxyRequestOrBuilder getKafkaMetaRequestOrBuilder() {
      if (kafkaMetaRequestBuilder_ != null) {
        return kafkaMetaRequestBuilder_.getMessageOrBuilder();
      } else {
        return kafkaMetaRequest_ == null ?
            io.datafibre.fibre.proto.PKafkaMetaProxyRequest.getDefaultInstance() : kafkaMetaRequest_;
      }
    }
    /**
     * <code>optional .starrocks.PKafkaMetaProxyRequest kafka_meta_request = 1;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        io.datafibre.fibre.proto.PKafkaMetaProxyRequest, io.datafibre.fibre.proto.PKafkaMetaProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaMetaProxyRequestOrBuilder>
        getKafkaMetaRequestFieldBuilder() {
      if (kafkaMetaRequestBuilder_ == null) {
        kafkaMetaRequestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            io.datafibre.fibre.proto.PKafkaMetaProxyRequest, io.datafibre.fibre.proto.PKafkaMetaProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaMetaProxyRequestOrBuilder>(
                getKafkaMetaRequest(),
                getParentForChildren(),
                isClean());
        kafkaMetaRequest_ = null;
      }
      return kafkaMetaRequestBuilder_;
    }

    private io.datafibre.fibre.proto.PKafkaOffsetProxyRequest kafkaOffsetRequest_;
    private com.google.protobuf.SingleFieldBuilderV3<
        io.datafibre.fibre.proto.PKafkaOffsetProxyRequest, io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaOffsetProxyRequestOrBuilder> kafkaOffsetRequestBuilder_;
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     * @return Whether the kafkaOffsetRequest field is set.
     */
    public boolean hasKafkaOffsetRequest() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     * @return The kafkaOffsetRequest.
     */
    public io.datafibre.fibre.proto.PKafkaOffsetProxyRequest getKafkaOffsetRequest() {
      if (kafkaOffsetRequestBuilder_ == null) {
        return kafkaOffsetRequest_ == null ? io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.getDefaultInstance() : kafkaOffsetRequest_;
      } else {
        return kafkaOffsetRequestBuilder_.getMessage();
      }
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    public Builder setKafkaOffsetRequest(io.datafibre.fibre.proto.PKafkaOffsetProxyRequest value) {
      if (kafkaOffsetRequestBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        kafkaOffsetRequest_ = value;
        onChanged();
      } else {
        kafkaOffsetRequestBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000002;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    public Builder setKafkaOffsetRequest(
        io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.Builder builderForValue) {
      if (kafkaOffsetRequestBuilder_ == null) {
        kafkaOffsetRequest_ = builderForValue.build();
        onChanged();
      } else {
        kafkaOffsetRequestBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000002;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    public Builder mergeKafkaOffsetRequest(io.datafibre.fibre.proto.PKafkaOffsetProxyRequest value) {
      if (kafkaOffsetRequestBuilder_ == null) {
        if (((bitField0_ & 0x00000002) != 0) &&
            kafkaOffsetRequest_ != null &&
            kafkaOffsetRequest_ != io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.getDefaultInstance()) {
          kafkaOffsetRequest_ =
            io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.newBuilder(kafkaOffsetRequest_).mergeFrom(value).buildPartial();
        } else {
          kafkaOffsetRequest_ = value;
        }
        onChanged();
      } else {
        kafkaOffsetRequestBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000002;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    public Builder clearKafkaOffsetRequest() {
      if (kafkaOffsetRequestBuilder_ == null) {
        kafkaOffsetRequest_ = null;
        onChanged();
      } else {
        kafkaOffsetRequestBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000002);
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    public io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.Builder getKafkaOffsetRequestBuilder() {
      bitField0_ |= 0x00000002;
      onChanged();
      return getKafkaOffsetRequestFieldBuilder().getBuilder();
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    public io.datafibre.fibre.proto.PKafkaOffsetProxyRequestOrBuilder getKafkaOffsetRequestOrBuilder() {
      if (kafkaOffsetRequestBuilder_ != null) {
        return kafkaOffsetRequestBuilder_.getMessageOrBuilder();
      } else {
        return kafkaOffsetRequest_ == null ?
            io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.getDefaultInstance() : kafkaOffsetRequest_;
      }
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetProxyRequest kafka_offset_request = 101;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        io.datafibre.fibre.proto.PKafkaOffsetProxyRequest, io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaOffsetProxyRequestOrBuilder>
        getKafkaOffsetRequestFieldBuilder() {
      if (kafkaOffsetRequestBuilder_ == null) {
        kafkaOffsetRequestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            io.datafibre.fibre.proto.PKafkaOffsetProxyRequest, io.datafibre.fibre.proto.PKafkaOffsetProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaOffsetProxyRequestOrBuilder>(
                getKafkaOffsetRequest(),
                getParentForChildren(),
                isClean());
        kafkaOffsetRequest_ = null;
      }
      return kafkaOffsetRequestBuilder_;
    }

    private io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest kafkaOffsetBatchRequest_;
    private com.google.protobuf.SingleFieldBuilderV3<
        io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest, io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequestOrBuilder> kafkaOffsetBatchRequestBuilder_;
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     * @return Whether the kafkaOffsetBatchRequest field is set.
     */
    public boolean hasKafkaOffsetBatchRequest() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     * @return The kafkaOffsetBatchRequest.
     */
    public io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest getKafkaOffsetBatchRequest() {
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        return kafkaOffsetBatchRequest_ == null ? io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.getDefaultInstance() : kafkaOffsetBatchRequest_;
      } else {
        return kafkaOffsetBatchRequestBuilder_.getMessage();
      }
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    public Builder setKafkaOffsetBatchRequest(io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest value) {
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        kafkaOffsetBatchRequest_ = value;
        onChanged();
      } else {
        kafkaOffsetBatchRequestBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000004;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    public Builder setKafkaOffsetBatchRequest(
        io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.Builder builderForValue) {
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        kafkaOffsetBatchRequest_ = builderForValue.build();
        onChanged();
      } else {
        kafkaOffsetBatchRequestBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000004;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    public Builder mergeKafkaOffsetBatchRequest(io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest value) {
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        if (((bitField0_ & 0x00000004) != 0) &&
            kafkaOffsetBatchRequest_ != null &&
            kafkaOffsetBatchRequest_ != io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.getDefaultInstance()) {
          kafkaOffsetBatchRequest_ =
            io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.newBuilder(kafkaOffsetBatchRequest_).mergeFrom(value).buildPartial();
        } else {
          kafkaOffsetBatchRequest_ = value;
        }
        onChanged();
      } else {
        kafkaOffsetBatchRequestBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000004;
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    public Builder clearKafkaOffsetBatchRequest() {
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        kafkaOffsetBatchRequest_ = null;
        onChanged();
      } else {
        kafkaOffsetBatchRequestBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000004);
      return this;
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    public io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.Builder getKafkaOffsetBatchRequestBuilder() {
      bitField0_ |= 0x00000004;
      onChanged();
      return getKafkaOffsetBatchRequestFieldBuilder().getBuilder();
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    public io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequestOrBuilder getKafkaOffsetBatchRequestOrBuilder() {
      if (kafkaOffsetBatchRequestBuilder_ != null) {
        return kafkaOffsetBatchRequestBuilder_.getMessageOrBuilder();
      } else {
        return kafkaOffsetBatchRequest_ == null ?
            io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.getDefaultInstance() : kafkaOffsetBatchRequest_;
      }
    }
    /**
     * <code>optional .starrocks.PKafkaOffsetBatchProxyRequest kafka_offset_batch_request = 102;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest, io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequestOrBuilder>
        getKafkaOffsetBatchRequestFieldBuilder() {
      if (kafkaOffsetBatchRequestBuilder_ == null) {
        kafkaOffsetBatchRequestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest, io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequest.Builder, io.datafibre.fibre.proto.PKafkaOffsetBatchProxyRequestOrBuilder>(
                getKafkaOffsetBatchRequest(),
                getParentForChildren(),
                isClean());
        kafkaOffsetBatchRequest_ = null;
      }
      return kafkaOffsetBatchRequestBuilder_;
    }

    private long timeout_ ;
    /**
     * <code>optional int64 timeout = 103;</code>
     * @return Whether the timeout field is set.
     */
    @java.lang.Override
    public boolean hasTimeout() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional int64 timeout = 103;</code>
     * @return The timeout.
     */
    @java.lang.Override
    public long getTimeout() {
      return timeout_;
    }
    /**
     * <code>optional int64 timeout = 103;</code>
     * @param value The timeout to set.
     * @return This builder for chaining.
     */
    public Builder setTimeout(long value) {
      bitField0_ |= 0x00000008;
      timeout_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>optional int64 timeout = 103;</code>
     * @return This builder for chaining.
     */
    public Builder clearTimeout() {
      bitField0_ = (bitField0_ & ~0x00000008);
      timeout_ = 0L;
      onChanged();
      return this;
    }
    @java.lang.Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:starrocks.PProxyRequest)
  }

  // @@protoc_insertion_point(class_scope:starrocks.PProxyRequest)
  private static final io.datafibre.fibre.proto.PProxyRequest DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new io.datafibre.fibre.proto.PProxyRequest();
  }

  public static io.datafibre.fibre.proto.PProxyRequest getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  @java.lang.Deprecated public static final com.google.protobuf.Parser<PProxyRequest>
      PARSER = new com.google.protobuf.AbstractParser<PProxyRequest>() {
    @java.lang.Override
    public PProxyRequest parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<PProxyRequest> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<PProxyRequest> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public io.datafibre.fibre.proto.PProxyRequest getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

